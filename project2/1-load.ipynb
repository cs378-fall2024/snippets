{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Create BQ dataset for storing the raw data"
      ],
      "metadata": {
        "id": "jjCBZFNK-Ajt"
      },
      "id": "jjCBZFNK-Ajt"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = \"cs378-fa2024\"\n",
        "dataset = \"air_travel_raw\"\n",
        "region = \"us-central1\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = bigquery.Dataset(f\"{project_id}.{dataset}\")\n",
        "dataset_id.location = region\n",
        "resp = bq_client.create_dataset(dataset_id, exists_ok=True)\n",
        "print(\"Created dataset {}.{}\".format(bq_client.project, resp.dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgmFndB9auLN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724549305011,
          "user_tz": 300,
          "elapsed": 357,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6c062d33-86da-47bb-e2a9-9e5430b4792e"
      },
      "id": "fgmFndB9auLN",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset cs378-fa2024.air_travel_raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common functions"
      ],
      "metadata": {
        "id": "dIpTO2xz-XIE"
      },
      "id": "dIpTO2xz-XIE"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = \"cs378-fa2024\"\n",
        "bucket = \"air-travel-data\"\n",
        "parent_folder = \"raw\"\n",
        "region = \"us-central1\"\n",
        "dataset = \"air_travel_raw\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "def create_load_table_from_csv(folder, file_name, table, schema, delimiter=\",\", quote_character=\"\\\"\"):\n",
        "\n",
        "  uri = f\"gs://{bucket}/{parent_folder}/{folder}/{file_name}\"\n",
        "  table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "\n",
        "  table = bigquery.Table(table_id, schema=schema)\n",
        "  table = bq_client.create_table(table, exists_ok=True)\n",
        "  print(\"Created table {}\".format(table.table_id))\n",
        "\n",
        "  # remove the data_source and load_time fields before loading the data,\n",
        "  # neither one is present in the csv\n",
        "  del schema[-1]\n",
        "  del schema[-1]\n",
        "  print(schema)\n",
        "\n",
        "  job_config = bigquery.LoadJobConfig(\n",
        "        schema=schema,\n",
        "        skip_leading_rows=1,\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        write_disposition=\"WRITE_TRUNCATE\",\n",
        "        field_delimiter=delimiter,\n",
        "        quote_character=quote_character,\n",
        "        allow_jagged_rows=True,\n",
        "        ignore_unknown_values=True\n",
        "      )\n",
        "\n",
        "  load_job = bq_client.load_table_from_uri(uri, table_id, job_config=job_config)\n",
        "  load_job.result()\n",
        "\n",
        "  destination_table = bq_client.get_table(table_id)\n",
        "  print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
        "\n",
        "\n",
        "\n",
        "def create_load_table_from_json(folder, file_name, table, schema):\n",
        "\n",
        "  table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "\n",
        "  table = bigquery.Table(table_id, schema=schema)\n",
        "  table = bq_client.create_table(table, exists_ok=True)\n",
        "  print(\"Created table {}\".format(table.table_id))\n",
        "\n",
        "  # remove the data_source and load_time fields before loading the data,\n",
        "  # neither one is present in the json\n",
        "  del schema[-1]\n",
        "  del schema[-1]\n",
        "\n",
        "  #print(schema)\n",
        "\n",
        "  job_config = bigquery.LoadJobConfig(schema=schema,\n",
        "      source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "      write_disposition = \"WRITE_TRUNCATE\"\n",
        "  )\n",
        "\n",
        "  uri = f\"gs://{bucket}/{parent_folder}/{folder}/{file_name}\"\n",
        "\n",
        "  load_job = bq_client.load_table_from_uri(\n",
        "      uri,\n",
        "      table_id,\n",
        "      location=region,\n",
        "      job_config=job_config,\n",
        "  )\n",
        "\n",
        "  load_job.result()\n",
        "\n",
        "  destination_table = bq_client.get_table(table_id)\n",
        "  print(\"Loaded {} rows.\".format(destination_table.num_rows))\n"
      ],
      "metadata": {
        "id": "EXGnLdb9-agW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724604360674,
          "user_tz": 300,
          "elapsed": 140,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "EXGnLdb9-agW",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and load `airport_businesses`"
      ],
      "metadata": {
        "id": "vK_VU2ioYUvb"
      },
      "id": "vK_VU2ioYUvb"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"airport-maps/out\"\n",
        "file_name = \"*.csv\"\n",
        "table = \"airport_businesses\"\n",
        "delimiter = \"\\t\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airport_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"terminal\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"business\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"category\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"location\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"menu_items\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'airportguide'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "id": "oWd7itfuYmwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724599020423,
          "user_tz": 300,
          "elapsed": 2680,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3bd75222-f7cf-496c-b2e7-7814e54b4131"
      },
      "id": "oWd7itfuYmwE",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airport_businesses\n",
            "[SchemaField('airport_code', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('terminal', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('business', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('category', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('location', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('menu_items', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 1574 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and load `flight_delays`"
      ],
      "metadata": {
        "id": "YShL34IqFVc-"
      },
      "id": "YShL34IqFVc-"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"on-time-performance\"\n",
        "file_name = \"*.csv\"\n",
        "table = \"flight_delays\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"year\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"month\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"carrier\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"carrier_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"arr_flights\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_del15\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"carrier_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"weather_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"nas_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"security_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"late_aircraft_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_cancelled\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_diverted\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"carrier_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"weather_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"nas_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"security_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"late_aircraft_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'transtats'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vSJRLZgFsgs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724600740941,
          "user_tz": 300,
          "elapsed": 10103,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0f1f378e-97cc-4bc3-d730-ac7b8222f3e3"
      },
      "id": "_vSJRLZgFsgs",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table flight_delays\n",
            "Loaded 381186 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and load `airlines`, `airports`, `countries`, `aircrafts`, and `flight_routes`\n",
        "#### Note: This dataset comes with 5 tables"
      ],
      "metadata": {
        "id": "Y0Wiral9N4GO"
      },
      "id": "Y0Wiral9N4GO"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"airlines.csv\"\n",
        "table = \"airlines\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airline_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"alias\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"callsign\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"country\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"active\", \"BOOL\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bmyjKSBOOBm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724601177990,
          "user_tz": 300,
          "elapsed": 2716,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "84c1db31-a10d-4ce5-e245-4aa64829ed53"
      },
      "id": "8bmyjKSBOOBm",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airlines\n",
            "Loaded 6162 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"airports_ext.csv\"\n",
        "table = \"airports\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"city\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"country\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"latitude\", \"BIGNUMERIC\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"longitude\", \"BIGNUMERIC\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"altitude\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"timezone\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"daylight_savings_time\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"tz_database_timezone\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"type\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yVzBiAcPbr2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724601540550,
          "user_tz": 300,
          "elapsed": 5215,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "db004f0b-6303-42e9-d816-b25d2b1edc25"
      },
      "id": "5yVzBiAcPbr2",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airports\n",
            "Loaded 12668 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"countries.csv\"\n",
        "table = \"countries\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"country_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iso_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dafif_code\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uR6KvyqQ1pq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724602057608,
          "user_tz": 300,
          "elapsed": 3111,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fc5733b2-6074-4a63-d18b-eb9425c41311"
      },
      "id": "2uR6KvyqQ1pq",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table countries\n",
            "Loaded 261 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"planes.csv\"\n",
        "table = \"aircrafts\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"aircraft_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Wh1xhsTE9p",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724602512421,
          "user_tz": 300,
          "elapsed": 3404,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "744de455-47e7-4176-cf7f-1dcb1ab60fca"
      },
      "id": "U_Wh1xhsTE9p",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table aircrafts\n",
            "Loaded 246 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"routes.csv\"\n",
        "table = \"flight_routes\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airline_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airline_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source_airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dest_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dest_airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"codeshare\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"stops\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"equipment\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6_RirNnUhFR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724602784232,
          "user_tz": 300,
          "elapsed": 3578,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e9c3af93-61ca-4982-ae04-7da587e9216d"
      },
      "id": "A6_RirNnUhFR",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table flight_routes\n",
            "Loaded 67663 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and load `airport_reviews`"
      ],
      "metadata": {
        "id": "l1CjL4vEWUpW"
      },
      "id": "l1CjL4vEWUpW"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"our-airports\"\n",
        "file_name = \"*.tsv\"\n",
        "table = \"airport_reviews\"\n",
        "delimiter = \"\\t\"\n",
        "quote_character = \"'\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"threadRef\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"airportRef\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"airportIdent\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"memberNickname\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"subject\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"body\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'ourairports'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter, quote_character)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q80Hi4IGWVC4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724604380556,
          "user_tz": 300,
          "elapsed": 3469,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ec0e4d04-14ea-440e-8ab3-70d545c7754a"
      },
      "id": "q80Hi4IGWVC4",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airport_reviews\n",
            "[SchemaField('id', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('threadRef', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('airportRef', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('airportIdent', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('date', 'DATETIME', 'NULLABLE', None, None, (), None), SchemaField('memberNickname', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('subject', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('body', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 15451 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and load tsa_reports"
      ],
      "metadata": {
        "id": "dLBwAyOWbypa"
      },
      "id": "dLBwAyOWbypa"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "table = \"tsa_traffic\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"date\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"hour\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"airport_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"city\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"state\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"checkpoint\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"total_count\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'tsa-foia'\"),\n",
        "    bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "# create table\n",
        "table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "print(\"Created table {}\".format(table.table_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaoRBX7Ab6C1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724611682152,
          "user_tz": 300,
          "elapsed": 385,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "beafa69a-6b60-4cc3-8488-5c6d83c82124"
      },
      "id": "AaoRBX7Ab6C1",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table tsa_traffic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "bucket = \"air-travel-data\"\n",
        "folder = \"raw/tsa-traffic/llm-text/\"\n",
        "\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# read files from GCS\n",
        "blobs = storage_client.list_blobs(bucket, prefix=folder)\n",
        "for blob in blobs:\n",
        "    file_path = \"/tmp/\" + blob.name.split(\"/\")[3]\n",
        "    print(f\"processing {file_path}\")\n",
        "    blob.download_to_filename(file_path)\n",
        "    rows_to_insert = convert_to_dict(file_path)\n",
        "    is_error = write_to_BQ(bq_client, table_id, rows_to_insert)\n",
        "\n",
        "    if is_error == True:\n",
        "        break\n",
        "    else:\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRADPZg-z9HK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724613213249,
          "user_tz": 300,
          "elapsed": 365740,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "85f70e8e-4ec5-4c49-fc19-7fec0e1297ef"
      },
      "id": "XRADPZg-z9HK",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing /tmp/april-14-2024-to-april-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-14-2024-to-april-20-2024_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/april-16-2023-to-april-22-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-16-2023-to-april-22-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/april-21-2024-to-april-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-21-2024-to-april-27-2024_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/april-23-2023-to-april-29-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-23-2023-to-april-29-2023_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/april-7-2024-to-april-13-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-7-2024-to-april-13-2024_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/april-9-2023-to-april-15-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-9-2023-to-april-15-2023_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/august-13-2023-to-august-19-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-13-2023-to-august-19-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/august-14-2022-to-august-20-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-14-2022-to-august-20-2022_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/august-20-2023-to-august-26-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-20-2023-to-august-26-2023_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/august-21-2022-to-august-27-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-21-2022-to-august-27-2022_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/august-6-2023-to-august-12-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-6-2023-to-august-12-2023_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/august-7-2022-to-august-13-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-7-2022-to-august-13-2022_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/december-10-2023-to-december-16-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-10-2023-to-december-16-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/december-11-2022-to-december-17-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-11-2022-to-december-17-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/december-17-2023-to-december-23-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-17-2023-to-december-23-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/december-24-2023-to-december-30-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-24-2023-to-december-30-2023_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/december-4-2022-to-december-10-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-4-2022-to-december-10-2022_501_994.txt\n",
            "write to BQ\n",
            "processing /tmp/february-12-2023-to-february-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-12-2023-to-february-18-2023_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/february-18-2024-to-february-24-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-18-2024-to-february-24-2024_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/february-19-2023-to-february-25-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-19-2023-to-february-25-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/february-4-2024-to-february-10-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-4-2024-to-february-10-2024_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/january-14-2024-to-january-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-14-2024-to-january-20-2024_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/january-15-2023-to-january-21-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-15-2023-to-january-21-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/january-21-2024-to-january-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-21-2024-to-january-27-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/january-22-2023-to-january-28-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-22-2023-to-january-28-2023_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/july-10-2022-to-july-16-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-10-2022-to-july-16-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/july-14-2024-to-july-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-14-2024-to-july-20-2024_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/july-16-2023-to-july-22-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-16-2023-to-july-22-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/july-21-2024-to-july-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-21-2024-to-july-27-2024_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/july-23-2023-to-july-29-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-23-2023-to-july-29-2023_501_983.txt\n",
            "*** Count must be an int, invalid value:  null\n",
            "write to BQ\n",
            "processing /tmp/july-24-2022-to-july-30-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-24-2022-to-july-30-2022_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/july-28-2024-to-august-3-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-28-2024-to-august-3-2024_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/july-7-2024-to-july-13-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-7-2024-to-july-13-2024_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/july-9-2023-to-july-15-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-9-2023-to-july-15-2023_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/june-11-2023-to-june-17-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-11-2023-to-june-17-2023_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/june-12-2022-to-june-18-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-12-2022-to-june-18-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/june-16-2024-to-june-22-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-16-2024-to-june-22-2024_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/june-18-2023-to-june-24-2023_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/june-23-2024-to-june-29-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-23-2024-to-june-29-2024_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/june-4-2023-to-june-10-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-4-2023-to-june-10-2023_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/june-9-2024-to-june-15-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-9-2024-to-june-15-2024_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/march-10-2024-to-march-16-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-10-2024-to-march-16-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-12-2023-to-march-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-12-2023-to-march-18-2023_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-17-2024-to-march-23-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-17-2024-to-march-23-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-19-2023-to-march-25-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-19-2023-to-march-25-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/march-24-2024-to-march-30-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-24-2024-to-march-30-2024_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/may-19-2024-to-may-25-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-19-2024-to-may-25-2024_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/may-21-2023-to-may-27-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-21-2023-to-may-27-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/may-5-2024-to-may-11-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-5-2024-to-may-11-2024_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/november-12-2023-to-november-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-12-2023-to-november-18-2023_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/november-13-2022-to-november-19-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-13-2022-to-november-19-2022_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/november-20-2022-to-november-26-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-20-2022-to-november-26-2022_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/november-5-2023-to-november-11-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-5-2023-to-november-11-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/october-15-2023-to-october-21-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-15-2023-to-october-21-2023_501_981.txt\n",
            "write to BQ\n",
            "processing /tmp/october-16-2022-to-october-22-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-16-2022-to-october-22-2022_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/october-22-2023-to-october-28-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-22-2023-to-october-28-2023_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/october-23-2022-to-october-29-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-23-2022-to-october-29-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/october-8-2023-to-october-14-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-8-2023-to-october-14-2023_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/september-4-2022-to-september-10-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/september-4-2022-to-september-10-2022_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_19_2017_to_november_25_2017_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_19_2017_to_november_25_2017_501_898.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_26_2017_to_december_02_2017_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_26_2017_to_december_02_2017_501_912.txt\n",
            "write to BQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def convert_to_dict(filepath):\n",
        "\n",
        "    rows_to_insert = []\n",
        "\n",
        "    for line_num, line in enumerate(list(open(filepath))):\n",
        "        #print(f\"{line_num}: {line}\")\n",
        "\n",
        "        if \"{\" == line.strip():\n",
        "            start_dict = line_num\n",
        "            #print(\"start_dict:\", start_dict)\n",
        "\n",
        "        if \"},\" in line.strip():\n",
        "            end_dict = line_num\n",
        "            #print(\"end_dict:\", end_dict)\n",
        "\n",
        "            dict_list = list(open(filepath))[start_dict+1:end_dict]\n",
        "            record = {}\n",
        "\n",
        "            for entry in dict_list:\n",
        "                entry_str = entry.replace(\"\\n\", \"\").replace(\",\", \"\")\n",
        "                key = entry_str.split(\":\")[0].replace('\"', '').strip()\n",
        "\n",
        "                if key in (\"hour_of_day\", \"Hour of Day\", \"hour of day\"):\n",
        "                    key = \"hour\"\n",
        "\n",
        "                if key in (\"Airport Code\", \"airport code\"):\n",
        "                    key = \"airport_code\"\n",
        "\n",
        "                if key in (\"Airport Name\", \"airport name\"):\n",
        "                    key = \"airport_name\"\n",
        "\n",
        "                if key in (\"Customer Traffic\", \"customer traffic\", \"customer_traffic\"):\n",
        "                    key = \"total_count\"\n",
        "\n",
        "                val = entry_str.split(\":\")[1].replace('\"', '').strip()\n",
        "\n",
        "                if key == \"total_count\":\n",
        "                    if val.isdigit():\n",
        "                        val = int(val)\n",
        "                    else:\n",
        "                        print(\"*** Count must be an int, invalid value: \", val)\n",
        "                        continue\n",
        "\n",
        "                record[key] = val\n",
        "\n",
        "            rows_to_insert.append(record)\n",
        "\n",
        "    return rows_to_insert\n",
        "\n",
        "\n",
        "def write_to_BQ(bq_client, table_id, rows_to_insert):\n",
        "\n",
        "    print(\"write to BQ\")\n",
        "    is_error = False\n",
        "\n",
        "    try:\n",
        "\n",
        "        table = bq_client.get_table(table_id)\n",
        "        schema = table.schema\n",
        "        del schema[-1]\n",
        "        del schema[-1]\n",
        "\n",
        "        job_config = bigquery.LoadJobConfig(schema=schema,\n",
        "                                            source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "                                            write_disposition='WRITE_APPEND')\n",
        "\n",
        "        load_job = bq_client.load_table_from_json(rows_to_insert, destination=table_id, job_config=job_config)\n",
        "        load_job.result()\n",
        "\n",
        "        if load_job.errors:\n",
        "            print('Errors while writing to table:', load_job.errors)\n",
        "            is_error = True\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Error while writing to table:', e)\n",
        "        if '404' in str(e):\n",
        "            # table isn't open for writes (it may have been just created)\n",
        "            print('Table not ready to be written to. Sleeping for 5 seconds.')\n",
        "            time.sleep(5)\n",
        "            try:\n",
        "                load_job = bq_client.load_table_from_json(rows_to_insert, destination=table_id, job_config=job_config)\n",
        "                load_job.result()\n",
        "            except Exception as e:\n",
        "                print('Error occurred while writing to table: {}'.format(e))\n",
        "                is_error = True\n",
        "\n",
        "    return is_error"
      ],
      "metadata": {
        "id": "jrkZeCI-eb95",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724612840472,
          "user_tz": 300,
          "elapsed": 112,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "jrkZeCI-eb95",
      "execution_count": 91,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "1-raw",
      "collapsed_sections": [
        "Y0Wiral9N4GO"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}